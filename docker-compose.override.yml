# x-airflow-common: &airflow-common
#   # In order to add custom dependencies or upgrade provider packages you can use your extended image.
#   # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
#   # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
#   # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.8.1}
#   build:
#     context: .
#     dockerfile: ${AIRFLOW_PROJ_DIR:-.}/airflow.extension.dockerfile
#   environment: &airflow-common-env
#     AIRFLOW__CORE__EXECUTOR: CeleryExecutor
#     AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
#     AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
#     AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
#     AIRFLOW__CORE__FERNET_KEY: ""
#     AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
#     AIRFLOW__CORE__LOAD_EXAMPLES: "true"
#     AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
#     # yamllint disable rule:line-length
#     # Use simple http server on scheduler for health checks
#     # See https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html#scheduler-health-check-server
#     # yamllint enable rule:line-length
#     AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
#     # WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
#     # for other purpose (development, test and especially production usage) build/extend Airflow image.
#     _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
#     PYTHONPATH: "/opt/airflow/backend:${PYTHONPATH}"
#   volumes:
#     - ./backend:/opt/airflow/backend
#     - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
#     - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
#     - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
#     - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
#   user: "${AIRFLOW_UID:-50000}:0"
#   depends_on: &airflow-common-depends-on
#     redis:
#       condition: service_healthy
#     postgres:
#       condition: service_healthy

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: frontend.dev.dockerfile
    volumes:
      - ./frontend/my-app:/usr/src/app
      - ./frontend/my-app/nginx.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "3001:3000"
      - "9229:9229"
    command: npm run start

  backend:
    command: >
      sh -c "python -Xfrozen_modules=off -m debugpy --listen 0.0.0.0:5678 -m
      uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 &
      watchmedo shell-command --patterns='*.py' --recursive --command='pytest' /usr/src/app"
    ports:
      - "5678:5678"

  # airflow-worker:
  #   <<: *airflow-common
  #   command: python -m debugpy --listen 0.0.0.0:5679 -m celery worker
  #   ports:
  #     - "5679:5679"
