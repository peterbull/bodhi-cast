{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import aiohttp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "import requests\n",
    "from sqlalchemy import (BigInteger, Boolean, Column, Float, Integer, String,\n",
    "                        and_, create_engine, select, text)\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "# from utils.models import SlSpots\n",
    "from utils.sl_models import SlSpots, SlRatings\n",
    "from utils.schemas import SlApiEndpoints, SlApiParams\n",
    "from utils.sl_data import SurflineSpots, SpotForecast\n",
    "from utils.utils import LOCAL_AIRFLOW_PG_URI, LOCAL_PG_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(LOCAL_AIRFLOW_PG_URI)\n",
    "SessionLocal = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "See `240220_sl_surf_spots.ipynb` for spot getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://services.surfline.com/taxonomy?type=taxonomy&id=58f7ed51dadb30820bb3879c&maxDepth=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You will not get Surfline forecast data without a valid Surfline premium login. Add your credentials to `.env.development`:\n",
    "  ```\n",
    "  SURFLINE_EMAIL=xxx\n",
    "  SURFLINE_PASSWORD=yyy\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Requests\n",
    "\n",
    "`https://services.surfline.com/kbyg/spots/forecasts/{type}?{params}`\n",
    "\n",
    "\n",
    "Type|Data\n",
    "----|----\n",
    "rating|array of human-readable and numeric (0-6) ratings\n",
    "wave|array of min/max sizes & optimal scores\n",
    "wind|array of wind directions/speeds & optimal scores\n",
    "tides|array of types & heights\n",
    "weather|array of sunrise/set times, array of temperatures/weather conditions\n",
    "\n",
    "Param|Values|Effect\n",
    "-----|------|------\n",
    "spotId|string|Surfline spot id that you want data for. A typical Surfline URL is `https://www.surfline.com/surf-report/venice-breakwater/590927576a2e4300134fbed8` where `590927576a2e4300134fbed8` is the `spotId`\n",
    "days|integer|Number of forecast days to get (Max 6 w/o access token, Max 17 w/ premium token)\n",
    "intervalHours|integer|Minimum of 1 (hour)\n",
    "maxHeights|boolean|`true` seems to remove min & optimal values from the wave data output\n",
    "sds|boolean|If true, use the new LOTUS forecast engine\n",
    "accesstoken|string|Auth token to get premium data access (optional)\n",
    "\n",
    "Anywhere there is an `optimalScore` the value can be interpreted as follows:\n",
    "\n",
    "Value|Meaning\n",
    "-----|-------\n",
    "0|Suboptimal\n",
    "1|Good\n",
    "2|Optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"rating\", \"wave\", \"wind\", \"tides\", \"weather\"]\n",
    "params = [\"spotId\", \"days\", \"intervalHours\", \"maxHeights\", \"sds\", \"accesstoken\"]\n",
    "base = \"https://services.surfline.com/kbyg/spots/forecasts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datapath/'spot_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the spot `id` for 1st Street Jetty in Va Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_id = df[df['names'].str.contains('1st Street Jetty', case=False, na=False)]['ids'].values[0]\n",
    "jetty_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_params = {params[0]: jetty_id}\n",
    "ex_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surfline seems to change their spot IDs periodically. Check a spot on the website and pass the objectId from the url as a param to debug if this is the case. If they've changed you'll need to run the notebook `240220_sl_surf_spots.ipynb` as mentioned above to refresh the spots dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_params = {params[0]: \"584204214e65fad6a7709ce7\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(f\"{base}/{types[0]}\", params=ex_params)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_json = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_day_json = res.json()\n",
    "if 'data' in four_day_json and 'rating' in four_day_json['data']:\n",
    "    four_day_json['data']['rating'] = four_day_json['data']['rating'][:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cull_extra_days(full_json):\n",
    "    if 'data' in full_json and 'rating' in full_json['data']:\n",
    "        full_json['data']['rating'] = full_json['data']['rating'][:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop extra days of forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cull_extra_days(four_day_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(four_day_json['data']['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a unix timestamp -> utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum.from_timestamp(rating_json['data']['rating'][0]['timestamp'], 'UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum.from_timestamp(rating_json['data']['rating'][int(72 / 3)-1]['timestamp'], 'UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `utcOffset` field seems to be aware that I'm working in EST currently. Either that or it's the time coding for the spot itself.\n",
    "\n",
    "Let's check a west coast spot to confirm how this is handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_jolla_id = df[df['names'].str.contains(\"La Jolla\", case=False, na=False)]['ids'].values[0]\n",
    "la_jolla_dict = {params[0]: la_jolla_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_jolla_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum.now(\"utc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {\"spot_id\": \"test\", \"spot_name\": \"test_2\", \"date\": pendulum.now(\"utc\"), \"forecast\": four_day_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_from_sl_api(endpoint: SlApiEndpoints, param_type: SlApiParams, param: str):\n",
    "    base_url = \"https://services.surfline.com/kbyg/spots/forecasts\"\n",
    "    res = requests.get(f\"{base_url}/{endpoint}\", params={param_type: param})\n",
    "    data = res.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = fetch_from_sl_api(SlApiEndpoints.RATING.value, SlApiParams.SPOT_ID.value, param=jetty_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_ratings = []\n",
    "for spot_id, spot_name in df[['ids', 'names']][:3].values:\n",
    "    res = requests.get(f\"{base}/rating\", params={'spotId': spot_id})\n",
    "    data = res.json()\n",
    "    cull_extra_days(data)\n",
    "    current_date = pendulum.now(\"utc\")\n",
    "    utc_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    data['spot_id'] = spot_id\n",
    "    data['spot_name'] = spot_name\n",
    "    data['utc_fetch_date'] = utc_date\n",
    "    spot_ratings.append(data)\n",
    "    # time.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_spot_ratings(df, ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum.from_timestamp(rating_json['data']['rating'][0]['timestamp'], 'UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.json_normalize(spot_ratings, record_path=['data', 'rating'], meta=['spot_id', 'spot_name', 'utc_fetch_date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['timestamp_utc'] = ratings_df['timestamp'].apply(lambda x: pendulum.from_timestamp(x).to_datetime_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so it looks like each spot's forecast starts at 12am *local time*, with the timestamp for that time in unix. To figure out the flat `UTC` time for each spot you can just apply the `utcOffset` that is included in response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['timestamp_utc'] = pd.to_datetime(ratings_df['timestamp_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['timestamp_utc'] = ratings_df.apply(lambda row: row['timestamp_utc'] + pd.Timedelta(hours=row['utcOffset']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as db:\n",
    "    matching_spots = []\n",
    "    for spot in df['names']:\n",
    "        stmt = text(\"\"\"select * from spots where spot_name like :spot\"\"\")\n",
    "        result = db.execute(stmt, {\"spot\": spot}).fetchall()\n",
    "        if len(result) > 0:\n",
    "            matching_spots.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_waves = fetch_from_sl_api(SlApiEndpoints.WAVE.value, SlApiParams.SPOT_ID.value, jetty_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_waves['associated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cull_extra_days(jetty_waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_waves['data']['wave'] = jetty_waves['data']['wave'][:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jetty_waves['data']['wave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_waves['associated']['spotId'] = jetty_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_waves['data']['spotId'] = jetty_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_meta_df = pd.json_normalize(jetty_waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_meta_df.drop(['permissions.violations', 'permissions.data', 'data.wave', 'data.spotId'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_wave_df = pd.json_normalize(\n",
    "    jetty_waves, record_path=[\"data\", \"wave\"], meta=[[\"data\", \"spotId\"]]\n",
    ")\n",
    "jetty_wave_df.drop(\"swells\", inplace=True, axis=1)\n",
    "jetty_wave_df.rename(columns={\"power\": \"wave_power\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jetty_wave_df['timestamp'] = jetty_wave_df['timestamp'].apply(lambda x: pendulum.from_timestamp(x).to_datetime_string())\n",
    "# jetty_wave_df['timestamp'] = pd.to_datetime(jetty_wave_df['timestamp'])\n",
    "# jetty_wave_df['timestamp_utc'] = jetty_wave_df.apply(lambda row: row['timestamp'] + pd.Timedelta(hours=row['utcOffset']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_wave_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_swell_df = pd.json_normalize(\n",
    "    jetty_waves,\n",
    "    record_path=['data', 'wave', 'swells'],\n",
    "    meta=[['data', 'wave', 'timestamp'], ['data', 'spotId']]\n",
    ")\n",
    "\n",
    "jetty_swell_df['swells_idx'] = jetty_swell_df.groupby('data.wave.timestamp').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_swell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_swell_df.rename({\"power\": 'swell_power'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_swell_df['data.wave.timestamp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_wave_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetty_swell_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waves_df = pd.merge(\n",
    "    jetty_wave_df,\n",
    "    jetty_swell_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"timestamp\", \"data.spotId\"],\n",
    "    right_on=[\"data.wave.timestamp\", 'data.spotId'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_waves_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waves_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waves_ratings_df = pd.merge(combined_waves_df, ratings_df, how='left', left_on=['timestamp', 'data.spotId'], right_on=['timestamp', 'spot_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waves_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_waves_ratings_df['timestamp'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['rating.value'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(jetty_meta_df, combined_waves_df, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(LOCAL_PG_URI)\n",
    "SessionLocal = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as db:\n",
    "    stmt = select(SlSpots.spot_id)\n",
    "    spots = db.execute(stmt).scalars().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sl_wave_data(data: Dict) -> pd.DataFrame:\n",
    "    if not data:\n",
    "        raise ValueError(\"Data is empty\")\n",
    "\n",
    "    meta_df = pd.json_normalize(data)\n",
    "    meta_df.drop(\n",
    "        [\"permissions.violations\", \"permissions.data\", \"data.wave\", \"data.spotId\"],\n",
    "        inplace=True,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    wave_df = pd.json_normalize(\n",
    "        jetty_waves, record_path=[\"data\", \"wave\"], meta=[[\"data\", \"spotId\"]]\n",
    "    )\n",
    "    wave_df.drop(\"swells\", inplace=True, axis=1)\n",
    "    wave_df.rename(columns={\"power\": \"wave_power\"}, inplace=True)\n",
    "\n",
    "    swell_df = pd.json_normalize(\n",
    "        jetty_waves,\n",
    "        record_path=[\"data\", \"wave\", \"swells\"],\n",
    "        meta=[[\"data\", \"wave\", \"timestamp\"], [\"data\", \"spotId\"]],\n",
    "    )\n",
    "\n",
    "    swell_df.rename(columns={\"power\": \"swell_power\"}, inplace=True)\n",
    "    swell_df[\"swells_idx\"] = swell_df.groupby(\"data.wave.timestamp\").cumcount()\n",
    "\n",
    "    combined_waves_df = pd.merge(\n",
    "        wave_df,\n",
    "        swell_df,\n",
    "        how=\"inner\",\n",
    "        left_on=[\"timestamp\", \"data.spotId\"],\n",
    "        right_on=[\"data.wave.timestamp\", \"data.spotId\"],\n",
    "    )\n",
    "\n",
    "    combined_df = pd.merge(meta_df, combined_waves_df, how='cross')\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for spot in spots[:2]:\n",
    "    result = fetch_from_sl_api(SlApiEndpoints.WAVE.value, SlApiParams.SPOT_ID.value, param=spot)\n",
    "    if result.get(\"associated\"):\n",
    "        result['associated']['spotId'] = spot\n",
    "        result['data']['spotId'] = spot\n",
    "    data.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([transform_sl_wave_data(entry) for entry in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SlRatings(Base):\n",
    "#     __tablename__ = 'sl_ratings'\n",
    "\n",
    "#     id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "#     associated_units_temperature = Column(String)\n",
    "#     associated_units_tideHeight = Column(String)\n",
    "#     associated_units_swellHeight = Column(String)\n",
    "#     associated_units_waveHeight = Column(String)\n",
    "#     associated_units_windSpeed = Column(String)\n",
    "#     associated_units_pressure = Column(String)\n",
    "#     associated_utcOffset = Column(Integer)\n",
    "#     associated_location_lon = Column(Float)\n",
    "#     associated_location_lat = Column(Float)\n",
    "#     associated_forecastLocation_lon = Column(Float)\n",
    "#     associated_forecastLocation_lat = Column(Float)\n",
    "#     associated_offshoreLocation_lon = Column(Float)\n",
    "#     associated_offshoreLocation_lat = Column(Float)\n",
    "#     associated_runInitializationTimestamp = Column(BigInteger)\n",
    "#     associated_spotId = Column(String)\n",
    "#     timestamp = Column(String)\n",
    "#     probability = Column(Float)\n",
    "#     utcOffset = Column(Integer)\n",
    "#     wave_power = Column(Float)\n",
    "#     surf_min = Column(Integer)\n",
    "#     surf_max = Column(Integer)\n",
    "#     surf_plus = Column(Boolean)\n",
    "#     surf_humanRelation = Column(String)\n",
    "#     surf_raw_min = Column(Float)\n",
    "#     surf_raw_max = Column(Float)\n",
    "#     surf_optimalScore = Column(Integer)\n",
    "#     data_spotId = Column(String)\n",
    "#     height = Column(Float)\n",
    "#     period = Column(Integer)\n",
    "#     impact = Column(Float)\n",
    "#     swell_power = Column(Float)\n",
    "#     direction = Column(Float)\n",
    "#     directionMin = Column(Float)\n",
    "#     optimalScore = Column(Integer)\n",
    "#     data_wave_timestamp = Column(String)\n",
    "#     swells_idx = Column(Integer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import SlRatings, create_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpotForecast:\n",
    "#     def __init__(self, database_uri):\n",
    "#         self.spots = []\n",
    "#         self.engine = create_engine(database_uri)\n",
    "#         self.SessionLocal = sessionmaker(bind=engine)\n",
    "\n",
    "\n",
    "#     def get_session(self):\n",
    "#         return self.SessionLocal()\n",
    "\n",
    "\n",
    "#     def fetch_all_forecasts(self) -> List[Dict[Any, Any]]:\n",
    "#         data = []\n",
    "#         for spot in self.spots[:2]:\n",
    "#             result = self.fetch_forecast(\n",
    "#                 SlApiEndpoints.WAVE.value, SlApiParams.SPOT_ID.value, param=spot\n",
    "#             )\n",
    "#             if result.get(\"associated\"):\n",
    "#                 result[\"associated\"][\"spotId\"] = spot\n",
    "#                 result[\"data\"][\"spotId\"] = spot\n",
    "#             data.append(result)\n",
    "#         return data\n",
    "\n",
    "\n",
    "#     def fetch_forecast(self, endpoint: SlApiEndpoints, param_type: SlApiParams, param: str) -> Dict[Any, Any]:\n",
    "#         base_url = \"https://services.surfline.com/kbyg/spots/forecasts\"\n",
    "#         res = requests.get(f\"{base_url}/{endpoint}\", params={param_type: param})\n",
    "#         data = res.json()\n",
    "#         return data\n",
    "\n",
    "\n",
    "#     def fetch_spots_from_db(self) -> None:\n",
    "#         with self.get_session() as db:\n",
    "#             stmt = select(SlSpots.spot_id)\n",
    "#             self.spots = db.execute(stmt).scalars().all()\n",
    "\n",
    "\n",
    "#     def transform_wave_data(self, data: Dict) -> List[Dict[Any, Any]]:\n",
    "#         if not data:\n",
    "#             raise ValueError(\"Data is empty\")\n",
    "\n",
    "#         meta_df = pd.json_normalize(data, sep=\"_\")\n",
    "#         meta_df.drop(\n",
    "#             [\"permissions_violations\", \"permissions_data\", \"data_wave\", \"data_spotId\"],\n",
    "#             inplace=True,\n",
    "#             axis=1,\n",
    "#         )\n",
    "\n",
    "#         wave_df = pd.json_normalize(\n",
    "#             jetty_waves, record_path=[\"data\", \"wave\"], meta=[[\"data\", \"spotId\"]], sep=\"_\"\n",
    "#         )\n",
    "#         wave_df.drop(\"swells\", inplace=True, axis=1)\n",
    "#         wave_df.rename(columns={\"power\": \"wave_power\"}, inplace=True)\n",
    "\n",
    "#         swell_df = pd.json_normalize(\n",
    "#             jetty_waves,\n",
    "#             record_path=[\"data\", \"wave\", \"swells\"],\n",
    "#             meta=[[\"data\", \"wave\", \"timestamp\"], [\"data\", \"spotId\"]],\n",
    "#             sep=\"_\",\n",
    "#         )\n",
    "\n",
    "#         swell_df.rename(columns={\"power\": \"swell_power\"}, inplace=True)\n",
    "#         swell_df[\"swells_idx\"] = swell_df.groupby(\"data_wave_timestamp\").cumcount()\n",
    "\n",
    "#         combined_waves_df = pd.merge(\n",
    "#             wave_df,\n",
    "#             swell_df,\n",
    "#             how=\"inner\",\n",
    "#             left_on=[\"timestamp\", \"data_spotId\"],\n",
    "#             right_on=[\"data_wave_timestamp\", \"data_spotId\"],\n",
    "#         )\n",
    "\n",
    "#         combined_df = pd.merge(meta_df, combined_waves_df, how=\"cross\")\n",
    "#         dict_record = combined_df.to_dict(\"records\")\n",
    "\n",
    "#         return dict_record\n",
    "\n",
    "\n",
    "#     def load_to_pg(self, dict_record: List[Dict[Any, Any]]) -> None:\n",
    "#         with self.get_session() as db:\n",
    "#             db.bulk_insert_mappings(SlRatings, dict_record)\n",
    "#             db.commit()\n",
    "\n",
    "#     def process_all_spot_ratings(self):\n",
    "#         self.fetch_spots_from_db()\n",
    "#         data = self.fetch_all_forecasts()\n",
    "#         for spot in data:\n",
    "#             record = self.transform_wave_data(spot)\n",
    "#             self.load_to_pg(record)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_forecast = SpotForecast(LOCAL_PG_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_forecast.process_all_spot_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_insert = spot_forecast.transform_wave_data(jetty_waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_insert_dict = test_insert.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_insert_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as db:\n",
    "    db.bulk_insert_mappings(SlRatings, test_insert_dict)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
